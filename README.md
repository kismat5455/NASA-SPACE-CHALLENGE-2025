# ğŸš€ NASA Research Assistant

A Retrieval-Augmented Generation (RAG) system for querying NASA research documents.

## ğŸŒŸ Features

- â˜ï¸ **Cloud Storage**: All documents stored in Pinecone - accessible from any device
- ğŸ” **Intelligent Document Search**: Query NASA research documents using natural language
- ğŸ¤– **Powered by Google Gemini**: Uses Gemini 2.5 for advanced reasoning
- ğŸ“¦ **LlamaIndex Framework**: Robust RAG implementation with cloud vector search
- ğŸŒ **Web Interface**: Beautiful Streamlit UI for interactive queries
- ğŸ“Š **Source Citations**: View relevant document excerpts with relevance scores
- ğŸ–¼ï¸ **Multimodal Support**: Extract and analyze images from PDFs

## ğŸ› ï¸ Technology Stack

- **LlamaIndex**: RAG framework for document indexing and retrieval
- **Google Gemini 2.5**: Advanced LLM for reasoning and generation
- **Pinecone**: Cloud vector database for scalable similarity search
- **Stella v5**: State-of-the-art local embeddings (1024 dimensions)
- **Streamlit**: Web interface for interactive queries
- **Python 3.13**: Core programming language

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- Google API Key (for Gemini access)
- Pinecone API Key (for cloud storage - free tier available)
- LLAMA_CLOUD_API_KEY(free tier available)

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
# Navigate to project directory
cd NASA-SPACE-CHALLENGE-2025

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure API Key

1. Get your Google API key from: https://makersuite.google.com/app/apikey
2. Create a `.env` file in the project root:

```bash
# Copy the example file
copy .env.example .env

# Edit .env and add your API key
GOOGLE_API_KEY=your_actual_api_key_here
```

### 3. Add NASA Documents

Place your NASA research documents in the `data/` folder:

```
data/
â”œâ”€â”€ research_paper_1.pdf
â”œâ”€â”€ technical_report.pdf
â”œâ”€â”€ mission_overview.txt
â””â”€â”€ ...
```

Supported formats: PDF, TXT, DOCX, MD

### 4. Index Documents

Run the document ingestion script to create the vector index:

```bash
python document_ingestion.py
```

This will:
- Load all documents from the `data/` folder
- Create embeddings using Gemini
- Store the vector index in `vector_store/`

### 5. Query Documents

**Option A: Web Interface (Recommended)**

```bash
streamlit run app.py
```

Then open your browser to http://localhost:8501

**Option B: Command Line Interface**

```bash
python query_engine.py
```

## ğŸ’¡ Usage

Simply upload your PDF documents through the web interface and start asking questions. The system will search through your documents and provide relevant answers with source citations.

## ğŸ—ï¸ Project Structure

```
NASA-SPACE-CHALLENGE-2025/
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ document_ingestion.py     # Document loading and indexing
â”œâ”€â”€ query_engine.py           # Query interface (CLI)
â”œâ”€â”€ app.py                    # Streamlit web interface
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env                      # API keys (create this)
â”œâ”€â”€ .env.example             # API key template
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ data/                    # Place your documents here
â””â”€â”€ vector_store/            # Vector index storage (auto-created)
```

## âš™ï¸ Configuration

Edit `config.py` to customize:

- **Model Selection**: Change models between Gemini 1.5 Flash or Pro
- **Chunk Size**: Adjust document chunking parameters
- **Top K Results**: Number of relevant documents to retrieve
- **Storage Paths**: Modify data and index directories

```python
# Example configuration changes
GEMINI_MODEL = "models/gemini-1.5-pro"  # Use Pro for better quality
CHUNK_SIZE = 2048                        # Larger chunks
TOP_K_RESULTS = 10                       # More sources
```

## ğŸ”§ Advanced Features

### Re-indexing Documents

To rebuild the index after adding new documents:

```bash
python document_ingestion.py
```

The system will detect and re-index all documents.

### Customizing Responses

Modify the temperature and response settings in `config.py` or directly in the code:

```python
Settings.llm = Gemini(
    model=config.GEMINI_MODEL,
    api_key=config.GOOGLE_API_KEY,
    temperature=0.7  # Lower for more focused, higher for creative
)
```




## ğŸ¤ Contributing

This project is for NASA Space Challenge 2025. Feel free to extend and improve it!

## ğŸ“ License

MIT License - Feel free to use and modify for your needs.

## ğŸ“š Resources

- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [Google Gemini API](https://ai.google.dev/)
- [NASA Open Data Portal](https://data.nasa.gov/)
- [Streamlit Documentation](https://docs.streamlit.io/)

